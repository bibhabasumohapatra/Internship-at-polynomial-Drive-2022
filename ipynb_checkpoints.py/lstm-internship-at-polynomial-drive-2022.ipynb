{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:21.934594Z","iopub.execute_input":"2022-02-16T19:38:21.934852Z","iopub.status.idle":"2022-02-16T19:38:23.380011Z","shell.execute_reply.started":"2022-02-16T19:38:21.934777Z","shell.execute_reply":"2022-02-16T19:38:23.37928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 8\nEPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:23.381554Z","iopub.execute_input":"2022-02-16T19:38:23.381792Z","iopub.status.idle":"2022-02-16T19:38:23.386841Z","shell.execute_reply.started":"2022-02-16T19:38:23.381759Z","shell.execute_reply":"2022-02-16T19:38:23.385421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AmazonDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, reviews, targets):\n\n        self.reviews = reviews\n        self.target = targets\n    def __len__(self):\n        return len(self.reviews)\n\n    def __getitem__(self, item):\n \n        review = self.reviews[item, :]\n        target = self.target[item]\n        return {\n            \"review\": torch.tensor(review, dtype=torch.long),\n            \"target\": torch.tensor(target, dtype=torch.float)\n        }","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T19:38:23.388119Z","iopub.execute_input":"2022-02-16T19:38:23.388615Z","iopub.status.idle":"2022-02-16T19:38:23.396813Z","shell.execute_reply.started":"2022-02-16T19:38:23.388561Z","shell.execute_reply":"2022-02-16T19:38:23.396082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, embedding_matrix):\n        super(LSTM, self).__init__()\n        \n        num_words = embedding_matrix.shape[0]\n        \n        embed_dim = embedding_matrix.shape[1]\n        \n        self.embedding = nn.Embedding(\n        num_embeddings=num_words,\n        embedding_dim=embed_dim\n        )\n        \n        self.embedding.weight = nn.Parameter(\n            torch.tensor(\n            embedding_matrix,\n            dtype=torch.float32\n            )\n        )\n        \n        self.embedding.weight.requires_grad = False\n        self.lstm = nn.LSTM(\n             embed_dim,\n             128,\n             bidirectional=True,\n             batch_first=True,\n             )\n        self.out = nn.Linear(512, 1)\n    def forward(self, x):\n         \n        x = self.embedding(x)\n        x, _ = self.lstm(x)\n        avg_pool = torch.mean(x, 1)\n        max_pool, _ = torch.max(x, 1)\n\n        out = torch.cat((avg_pool, max_pool), 1)\n        out = self.out(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:23.39951Z","iopub.execute_input":"2022-02-16T19:38:23.400116Z","iopub.status.idle":"2022-02-16T19:38:23.409298Z","shell.execute_reply.started":"2022-02-16T19:38:23.400079Z","shell.execute_reply":"2022-02-16T19:38:23.408417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    model.train()\n    for data in data_loader:\n        reviews = data[\"review\"]\n        targets = data[\"target\"]\n        reviews = reviews.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n        optimizer.zero_grad()\n        predictions = model(reviews)\n        loss = nn.BCEWithLogitsLoss()(\n                 predictions,\n                 targets.view(-1, 1)\n                 )\n        loss.backward()\n        optimizer.step()\n\ndef evaluate(data_loader, model, device):\n    final_predictions = []\n    final_targets = []\n    model.eval()\n    with torch.no_grad():\n        for data in data_loader:\n            reviews = data[\"review\"]\n            targets = data[\"target\"]\n            reviews = reviews.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n            predictions = model(reviews)\n\n            predictions = predictions.cpu().numpy().tolist()\n            targets = data[\"target\"].cpu().numpy().tolist()\n            final_predictions.extend(predictions)\n            final_targets.extend(targets)\n        \n    return final_predictions, final_targets\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:23.410469Z","iopub.execute_input":"2022-02-16T19:38:23.41085Z","iopub.status.idle":"2022-02-16T19:38:23.42149Z","shell.execute_reply.started":"2022-02-16T19:38:23.410812Z","shell.execute_reply":"2022-02-16T19:38:23.420697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# main.py","metadata":{}},{"cell_type":"code","source":"import io\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:23.423814Z","iopub.execute_input":"2022-02-16T19:38:23.42434Z","iopub.status.idle":"2022-02-16T19:38:28.425157Z","shell.execute_reply.started":"2022-02-16T19:38:23.424289Z","shell.execute_reply":"2022-02-16T19:38:28.424414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_vectors(fname):\n    fin = io.open(\n        fname,\n        'r',\n        encoding='utf-8',\n        newline='\\n',\n        errors='ignore'\n    )\n    n, d = map(int, fin.readline().split())\n    data = {}\n    for line in fin:\n        tokens = line.rstrip().split(' ')\n        data[tokens[0]] = list(map(float, tokens[1:]))\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:28.428347Z","iopub.execute_input":"2022-02-16T19:38:28.428565Z","iopub.status.idle":"2022-02-16T19:38:28.43612Z","shell.execute_reply.started":"2022-02-16T19:38:28.428537Z","shell.execute_reply":"2022-02-16T19:38:28.435407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_embedding_matrix(word_index, embedding_dict):\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in word_index.items():\n        if word in embedding_dict:\n            embedding_matrix[i] = embedding_dict[word]\n        \n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:28.437203Z","iopub.execute_input":"2022-02-16T19:38:28.438295Z","iopub.status.idle":"2022-02-16T19:38:28.444794Z","shell.execute_reply.started":"2022-02-16T19:38:28.438235Z","shell.execute_reply":"2022-02-16T19:38:28.443945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/amazon-dataset-csv-generator/PolynomialInternshipDrive2022.csv')\ndf_train, df_valid = train_test_split(df, test_size=0.3, random_state=42, stratify=df.overall.values)\ndf_train = df_train.reset_index(drop=True)\ndf_valid = df_valid.reset_index(drop=True)\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(df.review.values.tolist())\n\nxtrain = tokenizer.texts_to_sequences(df_train.review.values)\nxtest = tokenizer.texts_to_sequences(df_valid.review.values)\n\nxtrain = tf.keras.preprocessing.sequence.pad_sequences(\n xtrain, maxlen=MAX_LEN\n )\n\nxtest = tf.keras.preprocessing.sequence.pad_sequences(\n xtest, maxlen=MAX_LEN)\n\ntrain_dataset = AmazonDataset(\n reviews=xtrain,\n targets=train_df.overall.values\n )\ntrain_data_loader = torch.utils.data.DataLoader(\n train_dataset,\n batch_size=TRAIN_BATCH_SIZE,\n num_workers=0\n )\nvalid_dataset = dataset.IMDBDataset(\n reviews=xtest,\n targets=valid_df.overall.values\n )\nvalid_data_loader = torch.utils.data.DataLoader(\n valid_dataset,\n batch_size=VALID_BATCH_SIZE,\n num_workers=0\n )\nprint(\"Loading embeddings\")\n\nembedding_dict = load_vectors(\"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\")\nembedding_matrix = create_embedding_matrix(\n    tokenizer.word_index, embedding_dict\n )\ndevice = torch.device(\"cuda\")\nmodel = lstm.LSTM(embedding_matrix)\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nprint(\"Training Model\")\n\nbest_accuracy = 0\nearly_stopping_counter = 0\n\nfor epoch in range(EPOCHS):\n\n    engine.train(train_data_loader, model, optimizer, device)\n    \n    outputs, targets = engine.evaluate(\n    valid_data_loader, model, device\n    )\n    outputs = np.array(outputs) >= 0.5\n    accuracy = metrics.accuracy_score(targets, outputs)\n    print(\n    f\"Epoch: {epoch}, Accuracy Score = {accuracy}\"\n    )\n    # simple early stopping\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n    else:\n        early_stopping_counter += 1\n    if early_stopping_counter > 2:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:38:28.446223Z","iopub.execute_input":"2022-02-16T19:38:28.446614Z","iopub.status.idle":"2022-02-16T19:48:31.852124Z","shell.execute_reply.started":"2022-02-16T19:38:28.446577Z","shell.execute_reply":"2022-02-16T19:48:31.85123Z"},"trusted":true},"execution_count":null,"outputs":[]}]}